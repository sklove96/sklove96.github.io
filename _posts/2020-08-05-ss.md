---

layout: posts

title: "[Python] 파이썬(6) - 시각화2"

date: 2020-08-05

categories: [Python]

---

<br>

## 파이썬(6)

<br>

- - -

## (1) 퍼셉트론 

<br>


- ### 구조



![q](https://user-images.githubusercontent.com/67821750/89290508-ecd2dc80-d693-11ea-9255-31b17c29123c.png)

<br>

- ### 계산식


![qq](https://user-images.githubusercontent.com/67821750/89290555-06742400-d694-11ea-9aef-750e61e9f282.png)

```
Y: 출력신호
X: 입력신호
W1,w2: 가중치 (각 신호가 결과에 주는 영향력을 조절하는 요소로 작용)
B: 편향 (뉴런이 얼마나 쉽게 활성화되느냐를 제어)
```
<br>

- ### 편향(Bias)을 명시한 퍼셉트론

![w](https://user-images.githubusercontent.com/67821750/89290817-68348e00-d694-11ea-8e35-df9ca8288188.png)









<br>

## (2) 신경망

<br>

- ### 구조 (2층 신경망)



![a](https://user-images.githubusercontent.com/67821750/89290934-94500f00-d694-11ea-826e-3b615ebca35c.png)

<br>

- ### 활성화 함수 처리과정

<blockquote>활성화함수란, 입력 신호의 총합을 출력 신호로 변환하는 함수를 말한다.
또한, 입력 신호의 총합이 활성화를 일으키는지를 정하는 역할을 수행한다.
</blockquote>


<br>

- #### 계산식

![z](https://user-images.githubusercontent.com/67821750/89291169-032d6800-d695-11ea-9b20-ac0ade36cab7.png)

<br>

- #### 일반 뉴런과 비교

![zz](https://user-images.githubusercontent.com/67821750/89291230-21936380-d695-11ea-9a74-5dea93e34e6b.png)

<br>
<br>

- #### 함수 종류

<br>

##### (1) 계단함수(step function)


![1](https://user-images.githubusercontent.com/67821750/89291412-6ddea380-d695-11ea-8f45-831ece91d3cc.png)

![2](https://user-images.githubusercontent.com/67821750/89291433-7636de80-d695-11ea-9865-930bbcba0ab9.png)


<blockquote>임계값을 경계로 출력이 바뀌는 활성화 함수.
퍼셉트론에서는 활성화 함수로 계단 함수 이용하며
활성화 함수를 계단 함수에서 다른 함수로 변경하는 것이 신경망의 세계로 나아가는 열쇠이다.
</blockquote>

<br>
<br>

##### (2) 시그모이드 함수

![s](https://user-images.githubusercontent.com/67821750/89291587-c57d0f00-d695-11ea-87f4-c3fedbd77362.png)

![ss](https://user-images.githubusercontent.com/67821750/89291618-d3329480-d695-11ea-951e-6f73acec42b4.png)

<blockquote>신경망에서 자주 이용하는 활성화 함수로,
시그모이드 함수를 이용하여 신호를 변환하고, 그 변환된 신호를 다음 뉴런에 전달한다.
</blockquote>


<br>
<br>

- ##### 두 함수 비교

<br>

![f](https://user-images.githubusercontent.com/67821750/89291709-fe1ce880-d695-11ea-8dc6-8a0ad6fec80c.png)


<br>
<br>

##### (3) ReLU 함수(Rectified Linear Unit Function)

![x](https://user-images.githubusercontent.com/67821750/89291845-36bcc200-d696-11ea-969c-70dc98e48d95.png)

![xx](https://user-images.githubusercontent.com/67821750/89291862-3de3d000-d696-11ea-88b5-2fea0a616ed3.png)

<blockquote>최근 신경망 분야에서 이용되며,
입력이 0을 넘으면 그대로 출력, 0 이하이면 0 출력한다.
</blockquote>


<br>
<br>

